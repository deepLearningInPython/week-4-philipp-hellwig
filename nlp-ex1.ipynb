{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":763778,"sourceType":"datasetVersion","datasetId":362178},{"sourceId":112347694,"sourceType":"kernelVersion"}],"dockerImageVersionId":30301,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intro to neural language models](https://www.kaggle.com/learn/intro-to-deep-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/datasniffer/intro-neural-language-models).**\n\n\n\n---\n\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n    <strong>Accelerate Training with a Kaggle GPU!</strong><br>\nDid you know Kaggle offers free time with a GPU accelerator? You can speed up training neural networks in this course by switching to <strong>GPU</strong> in the <em>Accelerator</em> option on the right. (It may already be turned on.) Two things to be aware of:\n<ul>\n<li>Changing the <em>Accelerator</em> option will cause the notebook session to restart. You'll need to rerun any setup code.\n<li>You can have only one GPU session at a time, so be sure to shut the notebook down after you've finished the exercise.\n</ul>\n</blockquote>\n\n\n# Training a pre-trained BERT model to recognize equivalent sentence semantics\n    \nIn the tutorial you saw that BERT has been used as a basis for various tasks, including sentiment analysis and question answering, and another transformer based model (GPT2), can be used for text generation.\n\n<img src=\"https://i.imgur.com/HwfCw8S.png\" width=250 style=\"float:right;box-shadow:3px 3px 3px 3px gray\" />\n\nIn this exercise you will use BERT as a basis for training a model that can recognize whether two sentences are semantically equivalent. For example, the two sentences\n\n\n\n> 1. _But to see those pages, users would be required by Amazon to register, and Amazon plans to limit the amount of any single book a customer can view._\n> 2. _But to see those pages Amazon would require users to register, and it plans to limit the amount of any single book a browser can view.\"_\n\nconvey the same information, whereas the sentences\n\n> 1. _Dr. William Winkenwerder, assistant secretary of Defense for health affairs, said the vaccine poses little danger._\n> 2. _\"We stand behind this program,\" said Dr. William Winkenwerder, assistant secretary of defense for health affairs._\n\nconvey different information. Note that they are not conflicting—they just don't say the same thing.\n\nThis exercises is based on an [example from the HuggingFace documentation](https://huggingface.co/course/chapter3/3?fw=pt).\n\nBefore you start make sure that you can use the GPU accelerator! \n\nTo get started, run the code cell below to set everything up.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools_nlp_utility import *\n\nprint('Setup Complete')","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:13:52.559004Z","iopub.execute_input":"2024-11-18T22:13:52.559570Z","iopub.status.idle":"2024-11-18T22:14:08.630550Z","shell.execute_reply.started":"2024-11-18T22:13:52.559491Z","shell.execute_reply":"2024-11-18T22:14:08.629264Z"}},"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Loading the data\n\nWe will use a data set that is often used in _natural language inference_ (NLI) machine learning research, called [GLUE/MRPC](https://www.tensorflow.org/datasets/catalog/glue#gluemrpc).","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\nraw_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:14:08.632154Z","iopub.execute_input":"2024-11-18T22:14:08.632452Z","iopub.status.idle":"2024-11-18T22:14:11.338977Z","shell.execute_reply.started":"2024-11-18T22:14:08.632424Z","shell.execute_reply":"2024-11-18T22:14:11.338088Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221ee56bd67e4358b953274d4a41d956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79a299e748c4af1b7d785fb1eb7f4fb"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f83f101da6f47a3883c8fb04d254901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3a1f8d241a4d49ac4a5af7781db76a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5441fc275334dc8a1c1c4236d2e9d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9eaddd1bb5c485dbe403929b919c1af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbae18856989491dbcaa04b84e74d9d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8719155b164b49cf80aeac0fdb177dca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e44591044b414190847ba0449febab63"}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d89bcc53ff8418c9ae343be6f91c34f"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"The complete dataset comes in a special kind of dictionary (\"DatasetDict\") and consists of a _training_, a _validation_, and a _test_ set. Let's have look at the training set:","metadata":{}},{"cell_type":"code","source":"# Use pandas for a getting better look at the dataset:\nimport pandas as pd\n\npd.DataFrame(raw_datasets['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:14:11.340220Z","iopub.execute_input":"2024-11-18T22:14:11.341284Z","iopub.status.idle":"2024-11-18T22:14:11.602837Z","shell.execute_reply.started":"2024-11-18T22:14:11.341245Z","shell.execute_reply":"2024-11-18T22:14:11.601985Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              sentence1  \\\n0     Amrozi accused his brother , whom he called \" ...   \n1     Yucaipa owned Dominick 's before selling the c...   \n2     They had published an advertisement on the Int...   \n3     Around 0335 GMT , Tab shares were up 19 cents ...   \n4     The stock rose $ 2.11 , or about 11 percent , ...   \n...                                                 ...   \n3663  \" At this point , Mr. Brando announced : ' Som...   \n3664  Martin , 58 , will be freed today after servin...   \n3665  \" We have concluded that the outlook for price...   \n3666  The notification was first reported Friday by ...   \n3667  The 30-year bond US30YT = RR rose 22 / 32 for ...   \n\n                                              sentence2  label   idx  \n0     Referring to him as only \" the witness \" , Amr...      1     0  \n1     Yucaipa bought Dominick 's in 1995 for $ 693 m...      0     1  \n2     On June 10 , the ship 's owners had published ...      1     2  \n3     Tab shares jumped 20 cents , or 4.6 % , to set...      0     3  \n4     PG & E Corp. shares jumped $ 1.63 or 8 percent...      1     4  \n...                                                 ...    ...   ...  \n3663  Brando said that \" somebody ought to put a bul...      1  4071  \n3664  Martin served two thirds of a five-year senten...      0  4072  \n3665  In a statement , the ECB said the outlook for ...      1  4073  \n3666  MSNBC.com first reported the CIA request on Fr...      1  4074  \n3667  The 30-year bond US30YT = RR grew 1-3 / 32 for...      0  4075  \n\n[3668 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence1</th>\n      <th>sentence2</th>\n      <th>label</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amrozi accused his brother , whom he called \" ...</td>\n      <td>Referring to him as only \" the witness \" , Amr...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yucaipa owned Dominick 's before selling the c...</td>\n      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>They had published an advertisement on the Int...</td>\n      <td>On June 10 , the ship 's owners had published ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3663</th>\n      <td>\" At this point , Mr. Brando announced : ' Som...</td>\n      <td>Brando said that \" somebody ought to put a bul...</td>\n      <td>1</td>\n      <td>4071</td>\n    </tr>\n    <tr>\n      <th>3664</th>\n      <td>Martin , 58 , will be freed today after servin...</td>\n      <td>Martin served two thirds of a five-year senten...</td>\n      <td>0</td>\n      <td>4072</td>\n    </tr>\n    <tr>\n      <th>3665</th>\n      <td>\" We have concluded that the outlook for price...</td>\n      <td>In a statement , the ECB said the outlook for ...</td>\n      <td>1</td>\n      <td>4073</td>\n    </tr>\n    <tr>\n      <th>3666</th>\n      <td>The notification was first reported Friday by ...</td>\n      <td>MSNBC.com first reported the CIA request on Fr...</td>\n      <td>1</td>\n      <td>4074</td>\n    </tr>\n    <tr>\n      <th>3667</th>\n      <td>The 30-year bond US30YT = RR rose 22 / 32 for ...</td>\n      <td>The 30-year bond US30YT = RR grew 1-3 / 32 for...</td>\n      <td>0</td>\n      <td>4075</td>\n    </tr>\n  </tbody>\n</table>\n<p>3668 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# 1) Tokenizing and encoding the examples","metadata":{}},{"cell_type":"markdown","source":"As you can see from the display of the data set above, the data consists of pairs of strings (`sentence1` and `sentence2`), and a `label` that indicates whether the sentences are semantically equivalent.\n\nTo be able to use BERT, we need to tokenize and encode the string. From the tutorial, remember the encoding means that we represent each token by an integer. The integer is simply an index of which column in the matrix of embeddings that BERT has learned for each token. So, for instance the sentence\n\n> _\"the cat sat on the mat\"_\n\nmight be tokenized as\n\n```python\n[1, 10301, 45, 10, 1, 22387]\n```\n\nand if `X` is a matrix whose columns are word embeddings, the sentence would be represented by the matrix \n\n```python\nX[:,[1, 10301, 45, 10, 1, 22387]]\n```\n\nHowever, BERT represents a sentence little bit differently than 'simply a sequence of word embeddings':\n\n1. BERT doesn't use words as tokens, but word-pieces and punctuations\n2. BERT processes the initial token embeddings in a way that also encodes the context of the other tokens in the sentence.\n\nThe HuggingFace `transformer` library comes with an `AutoTokenizer` object that makes this easy. Because each language model may use different (types of) tokens and token encodings, we need to specify which pre-trained set of BERT model weights we are using:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# A specific set of pretrained weights for a model is called a 'checkpoint' in the HuggingFace library\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:14:53.700155Z","iopub.execute_input":"2024-11-18T22:14:53.700928Z","iopub.status.idle":"2024-11-18T22:14:56.309984Z","shell.execute_reply.started":"2024-11-18T22:14:53.700895Z","shell.execute_reply":"2024-11-18T22:14:56.309009Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"345308be879d4185aa589617d3eee53e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b73d1b6d84245beafb297c43d0c0a74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc6722fc59b4cbb8a32a7620e28c274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487b03dd0c8943f5ba3c09f6642473ed"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"The `tokenizer` has a method `encode` that be called with a string as argument, and returns the encoded representation of the string. Run this function on the sentence\n\n> _\"The cat sat on the mat\"_","metadata":{}},{"cell_type":"code","source":"# Run  on the sentence and store the result in tokinized_sentence \n\n# YOUR CODE (1 line of code)\ntokenized_sentence = tokenizer.encode(\"The cat sat on the mat\")\n\nprint(tokenized_sentence)\n\n# Check your work:\nq_1.check()\n\n# You can ask for a hint or the solution by uncommenting the following:\n#q_1.hint()\n#q_1.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:16:36.188594Z","iopub.execute_input":"2024-11-18T22:16:36.189262Z","iopub.status.idle":"2024-11-18T22:16:36.203929Z","shell.execute_reply.started":"2024-11-18T22:16:36.189230Z","shell.execute_reply":"2024-11-18T22:16:36.203112Z"}},"outputs":[{"name":"stdout","text":"[101, 1996, 4937, 2938, 2006, 1996, 13523, 102]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_SingleReviewMatch\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\n```python\n# Encode the sentence\ntokenized_sentence = tokenizer.encode('The cat sat on the mat')\n\n# this yields\n# [101, 1996, 4937, 2938, 2006, 1996, 13523, 102]\n\n```","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\n```python\n# Encode the sentence\ntokenized_sentence = tokenizer.encode('The cat sat on the mat')\n\n# this yields\n# [101, 1996, 4937, 2938, 2006, 1996, 13523, 102]\n\n```"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"How many tokens does the encoding of the sentence have? Is that more or less than what you'd expect if each _word_ had been encoded with a token?","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_1.solution2() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:16:46.647654Z","iopub.execute_input":"2024-11-18T22:16:46.648006Z","iopub.status.idle":"2024-11-18T22:16:46.654358Z","shell.execute_reply.started":"2024-11-18T22:16:46.647979Z","shell.execute_reply":"2024-11-18T22:16:46.653516Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<span style=color:#33cc99>Correct:</span>\n>\n> We expect 6 tokens, but the output has 8 tokens. This is because:\n>\n > 1. BERT tokenizer automatically adds a string **start** and string **end** token, and\n>\n> 2. BERT not only uses words as tokens, but also word parts, so that unfamiliar words can still be processed.","text/markdown":"<span style=color:#33cc99>Correct:</span>\n>\n> We expect 6 tokens, but the output has 8 tokens. This is because:\n>\n > 1. BERT tokenizer automatically adds a string **start** and string **end** token, and\n>\n> 2. BERT not only uses words as tokens, but also word parts, so that unfamiliar words can still be processed."},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"\n<br>\n\n#### Full encoding for BERT\n\nFor BERT this encoding is not enough. BERT not only requires a list of token ID's, but also an \"_attention mask_\" and a \"_token type ID_'s\". We won't go into what these are here, but we will need them to make BERT know what to do with the data. \n\nWe can get all the required encoding stuff for BERT if we use `tokenizer` as a function. Like so:","metadata":{}},{"cell_type":"code","source":"tokenizer('the cat sat on the mat')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:17:24.100815Z","iopub.execute_input":"2024-11-18T22:17:24.101155Z","iopub.status.idle":"2024-11-18T22:17:24.108069Z","shell.execute_reply.started":"2024-11-18T22:17:24.101127Z","shell.execute_reply":"2024-11-18T22:17:24.107131Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1996, 4937, 2938, 2006, 1996, 13523, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"#### Sentences pairs\n\nRemember that we have _two_ sentences in our data. Because one of the tasks that BERT was pre-trained on is a task in which BERT has to predict which of two sentences comes before the other, `tokenizer` also accepts two sentences. Furthermore, BERT can only handle sentences of limited length (max 512 tokens), and therefore `tokenizer` accepts the extra argument `truncation` which we can set tot `True` to truncate the sequence lengths to this upper limit:","metadata":{}},{"cell_type":"code","source":"tokenizer('the cat sat on the mat', 'the mouse danced on the table', truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:17:41.050936Z","iopub.execute_input":"2024-11-18T22:17:41.051333Z","iopub.status.idle":"2024-11-18T22:17:41.058525Z","shell.execute_reply.started":"2024-11-18T22:17:41.051287Z","shell.execute_reply":"2024-11-18T22:17:41.057529Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1996, 4937, 2938, 2006, 1996, 13523, 102, 1996, 8000, 10948, 2006, 1996, 2795, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"#### Tokenize and encode all the examples in the datasets\n\nWe need to do this for all the examples in `raw_datasets`, and to this end we define a helper function that takes one example and runs the tokenizer in the same way as before. Then we use the `map` method to run the functions on all the examples in `raw_datasets`:","metadata":{}},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:18:59.744019Z","iopub.execute_input":"2024-11-18T22:18:59.744890Z","iopub.status.idle":"2024-11-18T22:19:00.435086Z","shell.execute_reply.started":"2024-11-18T22:18:59.744855Z","shell.execute_reply":"2024-11-18T22:19:00.434216Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d330dcf7d2843f1a527a9c61ddbbbe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef7d0569a35401fb14a8d9af7d590e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31f5aaf4296349a9b145189de29ccc8e"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Now we have fully tokenized the datasets. If you want to have a look at how this changed the training set you can use pandas in the same way as above.","metadata":{}},{"cell_type":"code","source":"# You can use pandas DataFrame method to have a peek at what the tokenized training dataset looks like\n\n# YOUR CODE (1 line)\npd.DataFrame(tokenized_datasets['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:20:57.295684Z","iopub.execute_input":"2024-11-18T22:20:57.296500Z","iopub.status.idle":"2024-11-18T22:20:57.847105Z","shell.execute_reply.started":"2024-11-18T22:20:57.296462Z","shell.execute_reply":"2024-11-18T22:20:57.846291Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                              sentence1  \\\n0     Amrozi accused his brother , whom he called \" ...   \n1     Yucaipa owned Dominick 's before selling the c...   \n2     They had published an advertisement on the Int...   \n3     Around 0335 GMT , Tab shares were up 19 cents ...   \n4     The stock rose $ 2.11 , or about 11 percent , ...   \n...                                                 ...   \n3663  \" At this point , Mr. Brando announced : ' Som...   \n3664  Martin , 58 , will be freed today after servin...   \n3665  \" We have concluded that the outlook for price...   \n3666  The notification was first reported Friday by ...   \n3667  The 30-year bond US30YT = RR rose 22 / 32 for ...   \n\n                                              sentence2  label   idx  \\\n0     Referring to him as only \" the witness \" , Amr...      1     0   \n1     Yucaipa bought Dominick 's in 1995 for $ 693 m...      0     1   \n2     On June 10 , the ship 's owners had published ...      1     2   \n3     Tab shares jumped 20 cents , or 4.6 % , to set...      0     3   \n4     PG & E Corp. shares jumped $ 1.63 or 8 percent...      1     4   \n...                                                 ...    ...   ...   \n3663  Brando said that \" somebody ought to put a bul...      1  4071   \n3664  Martin served two thirds of a five-year senten...      0  4072   \n3665  In a statement , the ECB said the outlook for ...      1  4073   \n3666  MSNBC.com first reported the CIA request on Fr...      1  4074   \n3667  The 30-year bond US30YT = RR grew 1-3 / 32 for...      0  4075   \n\n                                              input_ids  \\\n0     [101, 2572, 3217, 5831, 5496, 2010, 2567, 1010...   \n1     [101, 9805, 3540, 11514, 2050, 3079, 11282, 22...   \n2     [101, 2027, 2018, 2405, 2019, 15147, 2006, 199...   \n3     [101, 2105, 6021, 19481, 13938, 2102, 1010, 21...   \n4     [101, 1996, 4518, 3123, 1002, 1016, 1012, 2340...   \n...                                                 ...   \n3663  [101, 1000, 2012, 2023, 2391, 1010, 2720, 1012...   \n3664  [101, 3235, 1010, 5388, 1010, 2097, 2022, 1065...   \n3665  [101, 1000, 2057, 2031, 5531, 2008, 1996, 1768...   \n3666  [101, 1996, 26828, 2001, 2034, 2988, 5958, 201...   \n3667  [101, 1996, 2382, 1011, 2095, 5416, 2149, 1414...   \n\n                                         token_type_ids  \\\n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n...                                                 ...   \n3663  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3664  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3665  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3666  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n3667  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                         attention_mask  \n0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n...                                                 ...  \n3663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[3668 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence1</th>\n      <th>sentence2</th>\n      <th>label</th>\n      <th>idx</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amrozi accused his brother , whom he called \" ...</td>\n      <td>Referring to him as only \" the witness \" , Amr...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[101, 2572, 3217, 5831, 5496, 2010, 2567, 1010...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yucaipa owned Dominick 's before selling the c...</td>\n      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[101, 9805, 3540, 11514, 2050, 3079, 11282, 22...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>They had published an advertisement on the Int...</td>\n      <td>On June 10 , the ship 's owners had published ...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[101, 2027, 2018, 2405, 2019, 15147, 2006, 199...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>[101, 2105, 6021, 19481, 13938, 2102, 1010, 21...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[101, 1996, 4518, 3123, 1002, 1016, 1012, 2340...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3663</th>\n      <td>\" At this point , Mr. Brando announced : ' Som...</td>\n      <td>Brando said that \" somebody ought to put a bul...</td>\n      <td>1</td>\n      <td>4071</td>\n      <td>[101, 1000, 2012, 2023, 2391, 1010, 2720, 1012...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3664</th>\n      <td>Martin , 58 , will be freed today after servin...</td>\n      <td>Martin served two thirds of a five-year senten...</td>\n      <td>0</td>\n      <td>4072</td>\n      <td>[101, 3235, 1010, 5388, 1010, 2097, 2022, 1065...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3665</th>\n      <td>\" We have concluded that the outlook for price...</td>\n      <td>In a statement , the ECB said the outlook for ...</td>\n      <td>1</td>\n      <td>4073</td>\n      <td>[101, 1000, 2057, 2031, 5531, 2008, 1996, 1768...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3666</th>\n      <td>The notification was first reported Friday by ...</td>\n      <td>MSNBC.com first reported the CIA request on Fr...</td>\n      <td>1</td>\n      <td>4074</td>\n      <td>[101, 1996, 26828, 2001, 2034, 2988, 5958, 201...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3667</th>\n      <td>The 30-year bond US30YT = RR rose 22 / 32 for ...</td>\n      <td>The 30-year bond US30YT = RR grew 1-3 / 32 for...</td>\n      <td>0</td>\n      <td>4075</td>\n      <td>[101, 1996, 2382, 1011, 2095, 5416, 2149, 1414...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3668 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"#### Convert to TensorFlow dataset\n\nTo get the encoded data sets ready for use with TensorFlow we still need to do one other conversion: First of all, all the examples need to be stored in `Tensor` arrays. Second, it will be convenient to have the data in a TensorFlow dataset format. \n\nThe `transformer` library has an object called `DataCollatorWithPadding` that can collate the examples into `Tensor` arrays, and at the same time makes sure that all examples will have the same length by padding shorter token sequences.\n\nThe TensorFlow dataset format distinguishes columns in the data frames are input variables and columns that are target variables. It also allows to set the `batch_size` that we want to use during training of the TensorFlow model. The `tokenized_datasets` has a method that uses this collator to turn the `tokenized_datasets` into the TensorFlow dataset format. We will use only a subset from both the training and the validation set to reduce computation times.","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\n# Make a data collator that turns examples into Tensor arrays\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n\n\n# Run the collator on the examples in the training set and store as a TensorFlow dataset\nuse_subset = range(0, len(tokenized_datasets['train']), 2) # change to maybe 5 if you don't have a GPU\ntf_train_dataset = tokenized_datasets[\"train\"].select(use_subset).to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    label_cols=[\"labels\"],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=16,\n)\n\n# Idem for the validation set\nuse_subset = range(0, len(tokenized_datasets['validation']), 2) # change to maybe 5 if you don't have a GPU\ntf_validation_dataset = tokenized_datasets[\"validation\"].select(use_subset).to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    label_cols=[\"labels\"],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=16,\n)\n\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:22:25.278117Z","iopub.execute_input":"2024-11-18T22:22:25.278860Z","iopub.status.idle":"2024-11-18T22:22:38.782227Z","shell.execute_reply.started":"2024-11-18T22:22:25.278827Z","shell.execute_reply":"2024-11-18T22:22:38.781344Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# 2) Load BERT into an `AutoModel`\n\nNow that we have made the data ready for TensorFlow, we need to build our TensorFlow/Keras model.\n\nTo use a pre-trained BERT model, we would like to use BERT to obtain contextualized representations of our text strings, and then use those representations downstream in further processing for a specific task. Doing that is a little bit more advanced and requires the \"_functional API_\" of Keras (see e.g., [this more advanced example](https://keras.io/examples/nlp/semantic_similarity_with_bert/) in the Keras documentation)\n\nHowever, the HuggingFace `transformer` library makes it much easier for us: It comes with a set objects which consist of a BERT part, and already has extra layers on top of it suitable for specific tasks. \n\nThe current task falls under 'sequence classification': Our `tokenizer` above has actually paste the two sentences of each example together in one sequence with a separation symbol in between the sentences (the `input_id` of the separation symbol is 102). So our model should learn to predict the value of `label` from this sequence. The AutoModel that is available for this task is called `AutoModelForSequenceClassification`—makes sense, right? \n\nBecause we want to work in this course only with TensorFlow (and not Pytorch), we need to prepend that name with `TF` and so the full name of the model that we'll use is `TFAutoModelForSequenceClassification`.\n\nFill in the `____` values below to get a list of items matching a single menu item.","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification\n\ncheckpoint = \"bert-base-uncased\" # we already specfied this for the tokenizer above; just repeated for clarity\nequivalence_model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:23:31.227818Z","iopub.execute_input":"2024-11-18T22:23:31.228431Z","iopub.status.idle":"2024-11-18T22:23:42.533088Z","shell.execute_reply.started":"2024-11-18T22:23:31.228397Z","shell.execute_reply":"2024-11-18T22:23:42.531870Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a92dfe4020124d3c81575605bd75d712"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Our `evquivalence_model` still needs to be trained. Because `equivalence_model` is simply a Tensorflow/Keras model, you can train it in the exact same way as all other Keras models.\n\nBut before we do this, let's verify that the model can be evaluated on the inputs as they are stored in `tf_train_dataset`. Below one of the examples is extracted, and the model is evaluated with the input part of the example","metadata":{}},{"cell_type":"code","source":"# TensorFlow datasets only allow the extraction of one element like this:\nfor inp, outp in tf_train_dataset:\n    break\n    \nequivalence_model(inp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:24:22.066848Z","iopub.execute_input":"2024-11-18T22:24:22.067229Z","iopub.status.idle":"2024-11-18T22:24:22.283829Z","shell.execute_reply.started":"2024-11-18T22:24:22.067201Z","shell.execute_reply":"2024-11-18T22:24:22.282908Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=\narray([[-0.80875385,  0.07910447],\n       [-0.8145871 ,  0.08410111],\n       [-0.7944824 ,  0.08282544],\n       [-0.81052554,  0.05559344],\n       [-0.8141959 ,  0.06977354],\n       [-0.79305977,  0.07821833],\n       [-0.8103473 ,  0.09315431],\n       [-0.792526  ,  0.07970342],\n       [-0.79805875,  0.08017459],\n       [-0.812222  ,  0.07938088],\n       [-0.81018376,  0.08954696],\n       [-0.7989375 ,  0.0895362 ],\n       [-0.81103384,  0.07151095],\n       [-0.8237512 ,  0.06362635],\n       [-0.8240591 ,  0.06784332],\n       [-0.80779415,  0.07784459]], dtype=float32)>, hidden_states=None, attentions=None)"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"Does the output shape conform to what you expect?","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.solution() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:25:26.954021Z","iopub.execute_input":"2024-11-18T22:25:26.954382Z","iopub.status.idle":"2024-11-18T22:25:26.961870Z","shell.execute_reply.started":"2024-11-18T22:25:26.954353Z","shell.execute_reply":"2024-11-18T22:25:26.960903Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"1_MenuAnalysisPlan\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: The output is an array with shape (16, 2). We indeed expect this, because there are 16 examples in a batch (see the creation of `tf_train_dataset` in section 1). Furthermore, there are two classes and hence, two logits, one for each class.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> The output is an array with shape (16, 2). We indeed expect this, because there are 16 examples in a batch (see the creation of `tf_train_dataset` in section 1). Furthermore, there are two classes and hence, two logits, one for each class."},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# 3) Compile the model\n\nAs with other Keras models we first need to `compile` our model. To do so we need to specify an optimizer, a loss function, and optionally some metrics we want to keep track of. \n\nBecause we are dealing with a classification problem here, we need the categorical crossentropy loss function (i.e., the log-likelihood function for mutlinomial logistic regression). Because `TFAutoModelForSequenceClassification` outputs _logits_ we need to specify this explicitely.\n\nWe'll use the Adam optimizer with training rate that is smaller than the default; and we'll keep track of the accuracy.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nopt = tf.keras.optimizers.Adam(1e-5)\nlogLike = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n# Compile equivalence_model with the above optimizer and loss function; keep track of accuracy\n# YOUR CODE (1 line of code)\nequivalence_model.compile(\n    optimizer=opt,\n    loss = logLike,\n    metrics=[\"accuracy\"]\n)\n \n# Print a summary of the model\nequivalence_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:28:00.030378Z","iopub.execute_input":"2024-11-18T22:28:00.031192Z","iopub.status.idle":"2024-11-18T22:28:00.305342Z","shell.execute_reply.started":"2024-11-18T22:28:00.031163Z","shell.execute_reply":"2024-11-18T22:28:00.304244Z"}},"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbert (TFBertMainLayer)       multiple                  109482240 \n_________________________________________________________________\ndropout_37 (Dropout)         multiple                  0         \n_________________________________________________________________\nclassifier (Dense)           multiple                  1538      \n=================================================================\nTotal params: 109,483,778\nTrainable params: 109,483,778\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Check your work\nq_3.check()\n \n# You can ask for a hint, or for the solution by uncommenting this:\n#q_3.hint()\n#\n#q_3.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:28:10.774174Z","iopub.execute_input":"2024-11-18T22:28:10.774878Z","iopub.status.idle":"2024-11-18T22:28:10.783349Z","shell.execute_reply.started":"2024-11-18T22:28:10.774843Z","shell.execute_reply":"2024-11-18T22:28:10.782470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_MatchAllDataset\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# 4) Train the model\n\nTrain the model on the training data set (using the `fit` method). Train for one epoch, and set `tf_validation_dataset` as the validation set. One epoch is enough, but more will give better results.","metadata":{}},{"cell_type":"code","source":"# Let equivalence_model train on the data in tf_train_dataset (make sure the output is stored in 'history')\nhistory = equivalence_model.fit(\n    tf_train_dataset,\n    epochs=1,\n    validation_data=tf_validation_dataset\n) \n\n# Check your work\nq_4.check()\n\n# Lines below will give you a hint or solution code\n#q_4.hint()\n#q_4.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:52:02.825049Z","iopub.execute_input":"2024-11-18T22:52:02.825755Z","iopub.status.idle":"2024-11-18T22:52:39.627505Z","shell.execute_reply.started":"2024-11-18T22:52:02.825719Z","shell.execute_reply":"2024-11-18T22:52:39.626594Z"}},"outputs":[{"name":"stdout","text":"114/114 [==============================] - 37s 322ms/step - loss: 0.0684 - accuracy: 0.9836 - val_loss: 0.8717 - val_accuracy: 0.7549\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"4_WorstReviewedItem\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"# 5) Test the model\n\nNext, we test the model. A simple test is to see how it performance on hand crafted examples. Consider the following example of two pairs of sentences: \n\nThe equivalent pair\n\n> 1. The earth revolves around the sun\n> 2. The sun is the pivot around which the earth circles\n\nand the unaffiliated pair\n\n> 1. The TV was broken\n> 2. The field area was larger than a pool\n\nRemember we first need to tokenize/encode these and wrap them into Tensors in order to be able to input them into our trained model:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Tokenize and encode\ntest_input = tokenize_function({\n    'sentence1': [\"The earth revolves around the sun\",\n                  \"The TV was broken\"], \n    'sentence2': [\"The sun is the pivot around which the earth circles\", \n                  \"The field area was larger than a pool\"],\n    })\n\n\n# Wrap into Tensors\ntest_input = data_collator(test_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:31:10.626170Z","iopub.execute_input":"2024-11-18T22:31:10.626932Z","iopub.status.idle":"2024-11-18T22:31:10.632425Z","shell.execute_reply.started":"2024-11-18T22:31:10.626898Z","shell.execute_reply":"2024-11-18T22:31:10.631514Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Let's see what the model tells us:\n{'predicted': tf.argmax(equivalence_model(test_input)[0].numpy(), axis=1).numpy(), 'truth': np.array([1,0])}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:31:18.642406Z","iopub.execute_input":"2024-11-18T22:31:18.643238Z","iopub.status.idle":"2024-11-18T22:31:18.756724Z","shell.execute_reply.started":"2024-11-18T22:31:18.643208Z","shell.execute_reply":"2024-11-18T22:31:18.755901Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'predicted': array([1, 0]), 'truth': array([1, 0])}"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"Of course this is only a small set of test sentence pairs. We have an additional test set in `raw_datasets` that we loaded at the start of this notebook. \n\nRun the `evaluate` function of our `equivalence_model` on this test set and store the return value of `evaluate` in a new variable called `test_score`. (_Hint_: don't forget to tokenize, encode, and `Tensor` wrap the test set examples!)","metadata":{}},{"cell_type":"code","source":"# Evaluate the equivalence_model on the test data set raw_datasets['test']\n\nuse_subset = range(0, len(tokenized_datasets[\"test\"]), 5)\n# YOUR CODE (two commands in approximately 9 lines of code)\n___\ntf_test_dataset = tokenized_datasets[\"test\"].select(use_subset).to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    label_cols=[\"labels\"],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=16,\n)\ntest_score = equivalence_model.evaluate(tf_test_dataset)\n\n# Print the evaluation output:\nprint(predictions)\n\n# Check your answer\nq_5.check()\n\n# Lines below will give you a hint or solution code\n#q_5.hint()\n#q_5.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T22:52:50.347145Z","iopub.execute_input":"2024-11-18T22:52:50.347505Z","iopub.status.idle":"2024-11-18T22:52:52.607484Z","shell.execute_reply.started":"2024-11-18T22:52:50.347475Z","shell.execute_reply":"2024-11-18T22:52:52.606661Z"}},"outputs":[{"name":"stdout","text":"22/22 [==============================] - 2s 97ms/step - loss: 0.8850 - accuracy: 0.7507\n[0.5587239265441895, 0.7275362610816956]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"5_CountImportanceQuestion\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\n```python\ntf_test_dataset = tokenized_datasets['test'].select(use_subset).to_tf_dataset(\n   columns=['attention_mask', 'input_ids', 'token_type_ids'],\n   label_cols=['labels'],\n   shuffle=False,\n   collate_fn=data_collator,\n   batch_size=16,\n)    \nequivalence_model.evaluate(tf_test_dataset)```","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\n```python\ntf_test_dataset = tokenized_datasets['test'].select(use_subset).to_tf_dataset(\n   columns=['attention_mask', 'input_ids', 'token_type_ids'],\n   label_cols=['labels'],\n   shuffle=False,\n   collate_fn=data_collator,\n   batch_size=16,\n)    \nequivalence_model.evaluate(tf_test_dataset)```\n"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"There you have it! You're accuracy is probably between 0.75 and 0.8, meaning that your model can decide on the equivalence of the two sentences \n\n> 1. The Russians have announced that they have to withdraw from Kherson, because of the highly effective counter offensive by the Ukranians.\n> 2. The Russian army has lost the battle for Kherson and are withdrawing their troops, due to the effectiveness of the Ukranians.\n\nwith close to 80% accuracy!","metadata":{}},{"cell_type":"markdown","source":"# Keep Going\n\nNow that you have seen the power of vector embeddings, let's see how they are created and **[learn how you can create your own](https://www.kaggle.com/datasniffer/nlp-token-embeddings)**. \n\n<!-- [learn how to create your own](#$NEXT_NOTEBOOK_URL$) -->","metadata":{}}]}